{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrantes\n",
    "- Aguilar Martínez Erick Yair\n",
    "- Martínez Muñoz Alan Magno\n",
    "- Mendoza Hernández Carlos Emiliano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador Bayesiano multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilidad a posteriori**:\n",
    "Es la probabilidad de que una observación pertenezca a una clase dada $y=k$ después de observar sus características, es decir, dado el vector de conteos\n",
    "$x$ de cada característica. Usando el teorema de Bayes, la probabilidad a posteriori para una clase $y=k$ dado un vector de características $x=(x_1,x_2,...,x_n)$ se expresa como:\n",
    "\n",
    "$$P(y=k|x)=\\frac{P(x|y=k)\\cdot P(y=k)}{P(x)}$$\n",
    "\n",
    "Aquí:\n",
    "- $P(y=k|x)$ es la probabilidad a posteriori de la clase $y=k$ dado el vector de características $x$.\n",
    "- $P(x|y=k)$ es la probabilidad de ver el vector $x$ (probabilidad condicional) en la clase $y=k$. En el clasificador multinomial, esta probabilidad se calcula como la probabilidad de observar un conjunto de conteos específicos para las características en la clase $k$.\n",
    "- $P(y=k)$ es la probabilidad a priori de la clase $k$.\n",
    "- $P(x)$ es la probabilidad marginal de observar el vector $x$ en cualquier clase. Como $P(x)$ es constante para todas las clases, se puede omitir al comparar entre clases (no afecta la selección de la clase con mayor probabilidad).\n",
    "\n",
    "Para simplificar el cálculo y evitar problemas numéricos, trabajamos con logaritmos. La expresión en logaritmos (omitimos $P(x)$ porque es constante) es:\n",
    "\n",
    "$$\\log P(y=k|x) \\propto \\log P(y=k) + \\sum_{j=1}^{n} x_j \\cdot \\log P(x_j|y=k) $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $\\log P(y=k)$ es el logaritmo de la probabilidad a priori de la clase $k$\n",
    "- $\\sum_{j=1}^{n}x_j \\cdot \\log P(x_j|y=k)$ es la suma de las contribuciones de cada característica al logaritmo de la probabilidad condicional, ponderada por el conteo $x_j$ de cada característica en el vector $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilidad a priori**: La probabilidad a priori en el contexto de un clasificador bayesiano multinomial es la probabilidad de que una observación pertenezca a una clase específica antes de ver las características de la observación. Esta probabilidad se basa en la frecuencia de las clases en el conjunto de datos de entrenamiento.\n",
    "\n",
    "La expresión matemática de la probabilidad a priori para una clase $y=k$\n",
    "$$P(y=k) = \\frac{\\text{Número de observaciones en la clase }k}{\\text{Número total de observaciones}}$$\n",
    "\n",
    "Dado que estamos trabajando con logaritmos para evitar problemas de precisión numérica, en la implementación usualmente calculamos el logaritmo de esta probabilidad, es decir:\n",
    "\n",
    "$$\\log P(y=k) = \\log \\left( \\frac{\\text{Número de observaciones en la clase }k}{\\text{Número total de observaciones}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilidades condicionales de las características dada una clase**:\n",
    "Las probabilidades condicionales de las características dada una clase en el clasificador bayesiano multinomial se refieren a la probabilidad de observar un conteo específico de una característica $x_j$ en una clase $y=k$. Estas probabilidades representan que tan probable es cada característica dentro de una clase en función de la frecuencia relativa de esa característica en los datos de entrenamiento.\n",
    "\n",
    "La expresión matemática para la probabilidad condicional de cada característica $x_j$ dado que la clase es $y=k$ es:\n",
    "\n",
    "$$P(x_j|y=k)=\\frac{\\text{Número de ocurrencias de } x_j \\text{ en la clase }k}{\\text{Número total de ocurrencias de todas las características de la clase }k}$$\n",
    "\n",
    "Para evitar problemas de precisión numérica, calculamos el logaritmo de las probabilidades condicionales. La expresión en logaritmo para $P(x_j|y=k)$ es entonces:\n",
    "\n",
    "$$ \\log P(x_j|y=k)= \\log \\left( \\frac{\\text{Número de ocurrencias de } x_j \\text{ en la clase }k}{\\text{Número total de ocurrencias de todas las características de la clase }k} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicción**:\n",
    "\n",
    "Se evalúa la expresión de la probabilidad a posteriori para cada clase, y se selecciona la clase con el mayor valor de $\\log P(y=k∣x)$ como la predicción.\n",
    "\n",
    "$$\\hat{y}=\\text{arg máx} _k \\left\\{ \\log P(y=k) + \\sum_{j=1}^{n} x_j \\cdot \\log P(x_j|y=k) \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{X} \\Rightarrow \\text{ matriz de contadores}$$ \n",
    "$$\\mathbf{y} \\Rightarrow \\text{ vector de clases para cada observación en }\\mathbf{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB:\n",
    "    \"\"\"\n",
    "    Multinomial Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \"\"\"\n",
    "        self.clases = None\n",
    "        self.cont_carac = None\n",
    "        self.prob_priori_log = None\n",
    "        self.prob_cond_carac_log = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model to the data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: np.array\n",
    "            Count matrix of shape (n_samples, n_features)\n",
    "        y: np.array\n",
    "            Class labels of shape (n_samples,)\n",
    "        Returns:\n",
    "        --------\n",
    "        np.array\n",
    "            Predicted class labels of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        # Probabilidad a priori de las clases\n",
    "        self.clases, counts = np.unique(y, return_counts=True)\n",
    "        # log (conteo de cada clase / total de observaciones)\n",
    "        self.prob_priori_log = np.log(counts / len(y))\n",
    "        # Probabilidad condicional de las características\n",
    "        self.cont_carac = np.zeros((len(self.clases), X.shape[1]))\n",
    "        for i, c in enumerate(self.clases):\n",
    "            X_c = X[y == c]\n",
    "            self.cont_carac[i, :] = np.sum(X_c, axis=0) + 1  # Suma 1 para evitar ceros\n",
    "        # log (conteo de las características en la clase / total de todos lso conteos en la clase)\n",
    "        self.prob_cond_carac_log = np.log(self.cont_carac / self.cont_carac.sum(axis=1, keepdims=True))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class labels.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: np.array\n",
    "            Count matrix of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "        --------\n",
    "        np.array\n",
    "            Predicted class labels of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        # Formulazo\n",
    "        probas = X @ self.prob_cond_carac_log.T + self.prob_priori_log\n",
    "        k_max = self.clases[np.argmax(probas, axis=1)]\n",
    "        return k_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "X = np.array([[2, 1, 0], [1, 3, 1], [0, 2, 4]])\n",
    "y = np.array([0, 1, 1])\n",
    "# Ajuste\n",
    "model.fit(X, y)\n",
    "# Predicción\n",
    "X_new = np.array([[1, 2, 0]])\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo SPAM (visto en clase con sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', names=['label', 'sms_message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df.label = df.label.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4179,), (1393,), (4179,), (1393,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], random_state=1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "train_vec = cv.fit_transform(X_train)\n",
    "test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = modelo.predict(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9856424982053122,\n",
       " 0.9545454545454546,\n",
       " 0.9333333333333333,\n",
       " 0.9438202247191011)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_test, y_hat)\n",
    "precision = precision_score(y_test, y_hat)\n",
    "recall = recall_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "accuracy, precision, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
